<h2 class="code-line" data-line-start=0 data-line-end=1 ><a id="____132____0"></a>Домашнее задание к занятию “13.2 разделы и монтирование”</h2>
<p class="has-line-data" data-line-start="2" data-line-end="4">Развертываем дополнительную машину nfspvc в облаке Яндекс<br>
Итого в наличии</p>
<pre><code>PS Q:\Netologia\Yandex&gt; yc compute instance list
+----------------------+--------+---------------+---------+---------------+-------------+
|          ID          |  NAME  |    ZONE ID    | STATUS  |  EXTERNAL IP  | INTERNAL IP |
+----------------------+--------+---------------+---------+---------------+-------------+
| ef3aelnrgn7busmnl4ng | node3  | ru-central1-c | RUNNING | 51.250.34.18  | 10.130.0.4  |
| ef3gbis3hpdbigjsivhq | node2  | ru-central1-c | RUNNING | 51.250.33.52  | 10.130.0.29 |
| ef3ho06cegqa3grje0m1 | cp1    | ru-central1-c | RUNNING | 51.250.32.100 | 10.130.0.27 |
| ef3pvt4t9ftltafa7qi6 | node1  | ru-central1-c | RUNNING | 51.250.33.14  | 10.130.0.15 |
| ef3vfu2suo5ua33onb3i | nfspvc | ru-central1-c | RUNNING | 51.250.44.26  | 10.130.0.31 |
+----------------------+--------+---------------+---------+---------------+-------------+
</code></pre>
<p class="has-line-data" data-line-start="15" data-line-end="16">На cp1 и Node 1,2,3 развертываем кластер спомощью kubespray</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ kubectl get nodes
NAME    STATUS   ROLES                  AGE     VERSION
cp1     Ready    control-plane,master   6h24m   v1.23.6
node1   Ready    &lt;none&gt;                 6h23m   v1.23.6
node2   Ready    &lt;none&gt;                 6h23m   v1.23.6
node3   Ready    &lt;none&gt;                 6h23m   v1.23.6
</code></pre>
<p class="has-line-data" data-line-start="23" data-line-end="25">На машине nfspvc  создаем .cube/config и копируем в файл содержимое с класетрного конфига<br>
Проводим установку NFS provider</p>
<pre><code>root@nfspvc:~/.kube#  helm install nfs-server stable/nfs-server-provisioner
WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config
WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config
WARNING: This chart is deprecated
NAME: nfs-server
LAST DEPLOYED: Wed May 25 16:01:36 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The NFS Provisioner service has now been installed.

A storage class named 'nfs' has now been created
and is available to provision dynamic volumes.

You can use this storageclass by creating a `PersistentVolumeClaim` with the
correct storageClassName attribute. For example:

    ---
    kind: PersistentVolumeClaim
    apiVersion: v1
    metadata:
      name: test-dynamic-volume-claim
    spec:
      storageClassName: &quot;nfs&quot;
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
</code></pre>
<p class="has-line-data" data-line-start="57" data-line-end="58">Появился  storageclasses</p>
<pre><code>mike@HOMEDX79SR:~$ kubectl get storageclasses.storage.k8s.io
NAME   PROVISIONER                                       RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs    cluster.local/nfs-server-nfs-server-provisioner   Delete          Immediate           true                   114s
</code></pre>
<p class="has-line-data" data-line-start="63" data-line-end="67">А также дополнительный сервис в кластере<br>
service/kubernetes                          ClusterIP      10.233.0.1      &lt;none&gt;        443/TCP                                                                                                     6h27m<br>
service/nfs-server-nfs-server-provisioner   ClusterIP      10.233.52.101   &lt;none&gt;        2049/TCP,2049/UDP,32803/TCP,32803/UDP,20048/TCP,20048/UDP,875/TCP,875/UDP,111/TCP,111/UDP,662/TCP,662/UDP   6h15m<br>
service/postgres                            LoadBalancer   10.233.44.162   &lt;pending&gt;     5432:30990/TCP</p>
<h1 class="code-line" data-line-start=68 data-line-end=69 ><a id="_1_______68"></a>Задание 1: подключить для тестового конфига общую папку</h1>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ cat shared-volume.yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-shared-volumes
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - mountPath: &quot;/ng&quot;
          name: s-vol
    - name: busybox
      image: busybox
      command: [&quot;sleep&quot;, &quot;3600&quot;]
      volumeMounts:
        - mountPath: &quot;/bs&quot;
          name: s-vol
  volumes:
    - name: s-vol
      emptyDir: {}mike@HOMEDX79SR:~/frontback/stage$ kubectl apply -f shared-volume.yaml
0


mike@HOMEDX79SR:~/frontback/stage$ kubectl get po
NAME                                  READY   STATUS    RESTARTS   AGE
nfs-server-nfs-server-provisioner-0   1/1     Running   0          3h2m
postgres-statefulset-0                1/1     Running   0          49m
test-shared-volumes                   2/2     Running   0          50s
mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c nginx -- ls -la /ng/
total 8
drwxrwxrwx 2 root root 4096 May 26 10:37 .
drwxr-xr-x 1 root root 4096 May 26 10:37 ..
mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c busybox -- ls -la /bs/
total 8
drwxrwxrwx    2 root     root          4096 May 26 10:37 .
drwxr-xr-x    1 root     root          4096 May 26 10:37 ..

mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c nginx -- sh -c 'echo &quot;test&quot; &gt; /ng/ng.txt'
mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c busybox -- sh -c 'echo &quot;test&quot; &gt; /bs/bs.txt'

mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c nginx -- ls -la /ng/
total 16
drwxrwxrwx 2 root root 4096 May 26 10:38 .
drwxr-xr-x 1 root root 4096 May 26 10:37 ..
-rw-r--r-- 1 root root    5 May 26 10:38 bs.txt
-rw-r--r-- 1 root root    5 May 26 10:38 ng.txt
mike@HOMEDX79SR:~/frontback/stage$ kubectl exec test-shared-volumes -c busybox -- ls -la /bs/
total 16
drwxrwxrwx    2 root     root          4096 May 26 10:38 .
drwxr-xr-x    1 root     root          4096 May 26 10:37 ..
-rw-r--r--    1 root     root             5 May 26 10:38 bs.txt
-rw-r--r--    1 root     root             5 May 26 10:38 ng.txt

mike@HOMEDX79SR:~/frontback/stage$ kubectl delete -f shared-volume.yaml
pod &quot;test-shared-volumes&quot; deleted
</code></pre>
<h1 class="code-line" data-line-start=126 data-line-end=127 ><a id="_2______126"></a>Задание 2: подключить общую папку для прода</h1>
<p class="has-line-data" data-line-start="127" data-line-end="128">Создаем PersistentVolumeClaim для NFS</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ cat  postgres-storage-nfs.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: postgres-pv-claim
spec:
  storageClassName: &quot;nfs&quot;
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 2Gi
      

Создаем claim     
mike@HOMEDX79SR:~/frontback/stage$kubectl apply -f postgres-storage-nfs.yaml
      
mike@HOMEDX79SR:~/frontback/stage$ kubectl get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
postgres-pv-claim   Bound    pvc-26476a63-49c6-4c2f-ba13-5e7ef82cba82   2Gi        RWX            nfs            4h6m
</code></pre>
<p class="has-line-data" data-line-start="150" data-line-end="151">Создаем под stateful для Postgrees</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ cat postgres-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-statefulset
spec:
  serviceName: postgres-service
  selector:
    matchLabels:
      app: postgres
  replicas: 1
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:13-alpine
          imagePullPolicy: &quot;IfNotPresent&quot;
          ports:
            - containerPort: 5432
          envFrom:
            - configMapRef:
                name: postgres-config
          volumeMounts:
            - mountPath: /data/pgdata
              name: postgredb
      volumes:
        - name: postgredb
          persistentVolumeClaim:
            claimName: postgres-pv-claim

mike@HOMEDX79SR:~/frontback/stage$ kubectl apply -f postgres-statefulset.yaml
</code></pre>
<p class="has-line-data" data-line-start="187" data-line-end="188">Создаем в другом поде Front И Back</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ cat fb_dep.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: frontback
  name: frontback
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: frontback
  template:
    metadata:
      labels:
        app: frontback
    spec:
      containers:
      - image: komarovma/devops-netology:frontend
        imagePullPolicy: IfNotPresent
        volumeMounts:
            - mountPath: /data/front
              name: postgredb
        name: frontend
      - image: komarovma/devops-netology:backend
        imagePullPolicy: IfNotPresent
        volumeMounts:
            - mountPath: /data/back
              name: postgredb
        name: backend
        env:
          - name: HTTP_PORT
            value: &quot;8080&quot;
      volumes:
        - name: postgredb
          persistentVolumeClaim:
            claimName: postgres-pv-claim

mike@HOMEDX79SR:~/frontback/stage$kubectl apply -f fb_dep.yaml
</code></pre>
<p class="has-line-data" data-line-start="230" data-line-end="231">Ввыводим список подов</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ kubectl get po
NAME                                  READY   STATUS    RESTARTS   AGE
frontback-5cd884dfd-mb569             2/2     Running   0          101m
nfs-server-nfs-server-provisioner-0   1/1     Running   0          6h10m
postgres-statefulset-0                1/1     Running   0          3h56m
</code></pre>
<p class="has-line-data" data-line-start="238" data-line-end="239">Сомтрим содержимое PV тома</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ kubectl exec postgres-statefulset-0 -- ls -la /data/pgdata
tl exec postgres-statefulset-0 -- sh -c 'echo &quot;test2&quot; &gt; /data/pgdata/pg.txt'total 12
drwxrwsrwx    2 root     root          4096 May 26 09:53 .
drwxr-xr-x    3 root     root          4096 May 26 09:49 ..
-rw-r--r--    1 root     root             6 May 26 09:53 test2.txt
Записываем на PV том
mike@HOMEDX79SR:~/frontback/stage$ kubectl exec postgres-statefulset-0 -- sh -c 'echo &quot;test2&quot; &gt; /data/pgdata/pg.txt'
</code></pre>
<p class="has-line-data" data-line-start="248" data-line-end="249">Смотри содержимое с другого пода</p>
<pre><code>mike@HOMEDX79SR:~/frontback/stage$ kubectl exec frontback-5cd884dfd-mb569 -c frontend -- ls -la /data/front
total 16
drwxrwsrwx 2 root root 4096 May 26 13:46 .
drwxr-xr-x 3 root root 4096 May 26 12:04 ..
-rw-r--r-- 1 root root    6 May 26 13:46 pg.txt
-rw-r--r-- 1 root root    6 May 26 09:53 test2.txt
</code></pre>